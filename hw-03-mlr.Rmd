---
title: "HW 03: Multiple Linear Regression"
author: "Hannah Wang"
date: "2019 October 2"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning=FALSE,
                      message=FALSE)
```

```{r load-packages}
library(tidyverse)
library(broom)
library(knitr) 
```

```{r load-data}
# for Question 8
houses <- read_csv("data/KingCountyHouses.csv")
```

### Question 1

Equation of model to estimate speed for fast track conditions:

speed-hat = 52.387 + 0.020 * year - 0.003 * starters 

### Question 2

Equation of model to estimate speed for slow track conditions:

speed-hat = 52.387 + 0.020 * year - 0.003 * starters - 1.070	* 0 - 2.183 * conditionslow + 0.012 * (year * 0) + 0.012 * (year * conditionslow)

= 52.387 + 0.020 * year - 0.003 * starters - 2.183 * conditionslow + 0.012 * (year * conditionslow)


### Question 3

The intercept (52.387 feet per second) describes the average speed for a winner in the year 1896, with a fast track condition, and racing with 0 horses. The intercept is not meaningful because it does not make sense for the winner to race against 0 horses.

### Question 4

The p-value testing differences in mean winning speed between fast and good track conditions in year 0 (with starters held constant) is 0.013. Since p<0.05, there is a significant difference between mean winning speed on fast and good track conditions.

### Question 5

The coeffecient for conditionsslow (assuming year = 0) shows that for all other variables held constant, the winner's speed is predicted, on average, to be 2.183 feet per second lower on a slow track than on a fast track.

### Question 6

The p-value testing if slope of year is the same for fast and good track conditions (with starters and year held constant) is 0.113. Since p>0.05, there is no significant difference between slope of year for fast and good track conditions.

### Question 7 

```{r crit-value}
qt(0.975, 115)
```

CI = slope of year for slow track ± t* SE(slope of year for slow track)

CI = 0.012 ± 0.004 t*

```{r conf-int}
0.012 - 0.004 * 1.980808
0.012 + 0.004 * 1.980808
```

We are 95% confident that the true difference between the slope of year for slow track conditions and the slope of year for fast track conditions lies between 0.00407 and 0.1992. In other words, we are 95% confident that for a one year increase, the winner's speed on a slow track is expected to increase, on average, by 0.004 to 0.020 feet per second more than the winner's speed on a fast track.

### Question 8

#### Introduction

```{r new-variables}
houses <- houses %>%
  filter(bedrooms <= 5 ) %>%
  mutate(floorsCat = as.factor(floors), 
         sqftCent = sqft - mean(sqft), 
         bedroomsCent = bedrooms - mean(bedrooms),
         bathroomsCent = bathrooms-mean(bathrooms),
         logprice = log(price))
```

#### Regression Model

Fit a regression model between logprice and predictor variables:

```{r model}
logprice_model <- lm(logprice ~ floorsCat + sqftCent + bedroomsCent + bathroomsCent + waterfront, data = houses)
kable(tidy(logprice_model, conf.int = TRUE, level = 0.95),digits=5)
```

logprice-hat = 13.015 + 0.184 * floorsCat1.5 - 0.002 * floorsCat2 + 0.206 * floorsCat2.5 + 0.214 * floorsCat3 + 0.273 * floorsCat3.5 + 0.0004 * sqftCent - 0.062 * bedroomsCent + 0.061 * bathroomsCent + 0.567 * waterfront

#### Exploratory Data Analysis 

```{r price-dist}
ggplot(data = houses, mapping = aes(x = price)) + geom_histogram() + labs(title = "Distribution of Price for Houses Sold in King County, Washington")
```

The distribution of house prices is unimodal and strongly right skewed due to high outliers of houses that are extremely expensive (up to around $6,0000,000). It is difficult to determine center and spread since the distribution is so strongly skewed and the wide range covers over 6,0000,0000. Thus, we visualize the distribution using the log transformed house prices.

```{r logprice-dist}
ggplot(data = houses, mapping = aes(x = logprice)) + geom_histogram() + labs(title = "Distribution of Logprice for Houses Sold in King County, Washington")
```

The distribution of logprice is unimodal and relatively normal and symmetric, centered around 13 with a range of about 3. We use the log-transformed version of price because it gives us a more normal distribution that is easier to analyze, as opposed to the extremely right skewed distribution of price, due to the high outliers from very expensive houses. The distribution of logprice better represents the data in terms of center, shape, and spread, thus making it more appropriate to use for our model.

Created scatterplots to visualize the relationship between logprice and predictor variables:

```{r pairs-logprice}
pairs(logprice ~ floorsCat + sqftCent + bedroomsCent + bathroomsCent + waterfront, data = houses, lower.panel = NULL)
```

#### Assumptions

##### Linearity

```{r linearity-plots}
ggplot(data = houses, mapping = aes(x = floorsCat, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Number of Floors")

ggplot(data = houses, mapping = aes(x = sqftCent, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Square Footage")

ggplot(data = houses, mapping = aes(x = bedroomsCent, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Number of Bedrooms")

ggplot(data = houses, mapping = aes(x = bathroomsCent, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Number of Bathrooms")

ggplot(data = houses, mapping = aes(x = waterfront, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Waterfont")
```

Linearity is satisfied for all predictor variables except number of floors because the scatterplots for the other variables show relatively positive correlations with logprice that follow a linear relationship, but the scatterplot between logprice and floorsCat does not follow a linear relationship.

##### Normality 

```{r resid}
houses <- houses %>%
  mutate(predicted = predict.lm(logprice_model), resid = residuals(logprice_model))
```

```{r resid-hist}
ggplot(data = houses, mapping = aes(x = resid)) + geom_histogram() + labs(title = "Distribution of Residuals")
```


```{r qqplot}
ggplot(data = houses, mapping = aes(sample = resid)) + 
  stat_qq() + 
  stat_qq_line() +
  labs(title = "Normal QQ Plot of Residuals")
```

Normality is satisfied because the distribution of residuals for the logprice model is normal and the normal qq plot of residuals follows the line of best fit.

##### Constant Variance

```{r resid-plot}
ggplot(data = houses, mapping = aes(x = predicted, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Predicted Logprice")

ggplot(data = houses, mapping = aes(x = floorsCat, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Number of Floors")

ggplot(data = houses, mapping = aes(x = sqftCent, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Interior Square Footage")

ggplot(data = houses, mapping = aes(x = bedroomsCent, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Number of Bedrooms")

ggplot(data = houses, mapping = aes(x = bathroomsCent, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Number of Bathrooms")

ggplot(data = houses, mapping = aes(x = as.factor(waterfront), y = resid)) + geom_boxplot() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Waterfront")
```

Constant Variance is not satsified for any of the predictor variables because the the variation in residuals are not constant across any of the predictor variables.

##### Independence

Independence is not satisfied because a house's price is not completely indpendent of other houses' prices. For example, if the economy is not doing well, house prices might decrease in general, or houses might be priced lower relative to other houses to compete in the market. Also, houses in the same neighborhood might all be priced similarly because they are built the same way and attract the same demographics.

#### Inference and Prediction

##### Relationship between House Price and Square Footage: 

For every 1 square foot increase in a house's interior square footage, we expect the median price to be multiplied by a factor of $1.0004. We are 95% confident that for a 1 square foot increase in a house's interior square footage, we can expect the median price to be multiplied by a factor of 1.00039 to 1.00041.

##### Relationship between House Price and Number of Floors:

A house with 1.5 floors is expected to have a median price 1.202 times the price of a 1-floor house. A house with 2 floors is expected to have a median price 0.998 times the price of a 1-floor house. A house with 2.5 floors is expected to have a median price 1.229 times the price of a 1-floor house. A house with 3 floors is expected to have a median price 1.238 times the price of a 1-floor house. A house with 3.5 floors is expected to have a median price 1.314 times the price of a 1-floor house. 

The null hypothesis states that there is no statistically significant difference in house price between houses with 1 floor and 1.5, 2, 2.5, 3, and 3.5 floors. The alternative hypothesis states that there is a statistically significant difference in house prices between houses with different number of floors. 

H0: μ1=μ1.5=μ2=μ2.5=μ3=μ3.5

Ha: At least one μ is not equal to the others

The differences in house price are statistically significant for all floors except between houses with 1 floor and 2 floors. This is because the p-value for 2 floor houses is 0.765, which is greater than the alpha level of 0.05, thus we fail to reject the null hypothesis, showing there is no statisically significant difference in house price betwen houses with 1 and 2 floors.

#### Interaction

```{r plot-interaction}
ggplot(data = houses, mapping = aes(x = bedroomsCent, y = logprice, color = waterfront)) + geom_point()
```

According to the scatterplot, for a given number of bedrooms, it seems that houses with a waterfront tend to have higher prices than houses without a waterfront. However, we need to see if this interaction difference is actually significant.

```{r model-interaction}
logprice_model <- lm(logprice ~ floorsCat + sqftCent + bedroomsCent + bathroomsCent + waterfront + waterfront * bedroomsCent, data = houses)
kable(tidy(logprice_model, conf.int = TRUE, level = 0.95),digits=5)
```

The model with the bedroomsCent:waterfront interaction variable included gives a p-value of 0.486 for the bedroomsCent:waterfont variable. Because the p-value is greater than the alpha level of 0.05, the interaction between `waterfront` and `bedroomsCent` is not significant.

### Overall (do not delete!)

