---
title: "HW 03: Multiple Linear Regression"
author: "Hannah Wang"
date: "2019 October 2"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning=FALSE,
                      message=FALSE)
```

```{r load-packages}
library(tidyverse)
library(broom)
library(knitr) 
```

```{r load-data}
# for Question 8
houses <- read_csv("data/KingCountyHouses.csv")
```

### Question 1

For fast track conditions: 

speed-hat = 52.387 + 0.020 * year - 0.003 * starters 

### Question 2

For slow  track conditions: 

speed-hat = 52.387 + 0.020 * year - 0.003 * starters - 1.070	* 0 - 2.1834 * 1 + 0.012 * (year x 0) + 0.012 * (year x 1)

= 50.2036 + 0.032 * year - 0.003 * starters

### Question 3

The intercept (52.387 feet per second) describes the average speed for a winner in the year 1896, with a fast track condition, and racing with 0 horses. The intercept is not meaningful because it does not make sense for the winner to race against 0 horses.

### Question 4

The p-value is 0.013. We use the p-value in the conditiongood variable row because that is the p-value we get from comparing good track conditions to the baseline condition of fast track. Since year = 0, we don't have to worry about the interaction variables.

### Question 5

All other variables held constant, the winner's speed is predicted, on average, to be 2.183 feet per second lower on a slow track than on a fast track.

### Question 6

The p-value is 0.113. We use the p-value in the year:conditiongood interaction variable row.

### Question 7 

```{r crit-value}
qt(0.975, 115)
```

CI = slope of year for slow track ± t* SE(slope of year for slow track)

CI = 0.012 ± 0.004 t*

```{r conf-int}
0.012 - 0.004 * 1.980808
0.012 + 0.004 * 1.980808
```

We are 95% confident that the true difference between the slope of year for slow track conditions and the slope of year for fast track conditions lies between 0.00407 and 0.1992. In other words, we are 95% confident that for a one year increase, the winner's speed on a slow track is expected to increase, on average, by 0.004 to 0.020 feet per second more than the winner's speed on a fast track.

### Question 8

#### Introduction

```{r new-variables}
houses <- houses %>%
  filter(bedrooms <= 5 ) %>%
  mutate(floorsCat = as.factor(floors), 
         sqftCent = sqft - mean(sqft), 
         bedroomsCent = bedrooms - mean(bedrooms),
         bathroomsCent = bathrooms-mean(bathrooms),
         logprice = log(price))
```

#### Regression Model

Fit a regression model between logprice and predictor variables:

```{r model}
logprice_model <- lm(logprice ~ floorsCat + sqftCent + bedroomsCent + bathroomsCent + waterfront, data = houses)
kable(tidy(logprice_model, conf.int = TRUE, level = 0.95),digits=5)
```

logprice-hat = 13.015 + 0.184 * floorsCat1.5 - 0.002 * floorsCat2 + 0.206 * floorsCat2.5 + 0.214 * floorsCat3 + 0.273 * floorsCat3.5 + 0.0004 * sqftCent - 0.062 * bedroomsCent + 0.061 * bathroomsCent + 0.567 * waterfront

#### Exploratory Data Analysis 

```{r price-dist}
ggplot(data = houses, mapping = aes(x = price)) + geom_histogram() + labs(title = "Distribution of Price for Houses Sold in King County, Washington")
```

The distribution of house prices is unimodal and strongly right skewed due to high outliers of houses that are extremely expensive. Thus, we visualize the distribution using the log transformed house prices.

```{r logprice-dist}
ggplot(data = houses, mapping = aes(x = logprice)) + geom_histogram() + labs(title = "Distribution of Logprice for Houses Sold in King County, Washington")
```

The distribution of logprice is unimodal and relatively normal. We use the log-transformed version of price because it gives us a more normal distribution that is more spread out and easier to analyze, as opposed to the clustered and extremely right skewed distribution of price, due to the high outliers from very expensive houses.

Created scatterplots to visualize the relationship between logprice and predictor variables:

```{r pairs-logprice}
pairs(logprice ~ floorsCat + sqftCent + bedroomsCent + bathroomsCent + waterfront, data = houses, lower.panel = NULL)
```

#### Discussion

Relationship between House Price and Square Footage: 

For every 1 square foot increase in a house's interior square footage, we expect the median price to be multiplied by a factor of $1.0004. We are 95% confident that for a 1 square foot increase in a house's interior square footage, we can expect the median price to be multiplied by a factor of 1.00039 to 1.00041.

Relationship between House Price and Number of Floors:

A house with 1.5 floors is expected to have a median price 1.202 times the price of a 1-floor house. A house with 2 floors is expected to have a median price 0.998 times the price of a 1-floor house. A house with 2.5 floors is expected to have a median price 1.229 times the price of a 1-floor house. A house with 3 floors is expected to have a median price 1.238 times the price of a 1-floor house. A house with 3.5 floors is expected to have a median price 1.314 times the price of a 1-floor house. 

The null hypothesis states that there is no statistically significant difference in house price between houses with 1 floor and 1.5, 2, 2.5, 3, and 3.5 floors. The alternative hypothesis states that there is a statistically significant difference in house prices between houses with different number of floors. 

The differences in house price are statistically significant for all floors except between houses with 1 floor and 2 floors. This is because the p-value for 2 floor houses is 0.765, which is greater than the alpha level of 0.05, thus we fail to reject the null hypothesis, showing there is no statisically significant difference in house price betwen houses with 1 and 2 floors.

#### Assumptions

```{r linearity-plots}
ggplot(data = houses, mapping = aes(x = floorsCat, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Number of Floors")

ggplot(data = houses, mapping = aes(x = sqftCent, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Square Footage")

ggplot(data = houses, mapping = aes(x = bedroomsCent, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Number of Bedrooms")

ggplot(data = houses, mapping = aes(x = bathroomsCent, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Number of Bathrooms")

ggplot(data = houses, mapping = aes(x = waterfront, y = logprice)) + geom_point() + labs(title = "Relationship between Logprice and Waterfont")
```

```{r resid}
houses <- houses %>%
  mutate(predicted = predict.lm(logprice_model), resid = residuals(logprice_model))
```

```{r resid-hist}
ggplot(data = houses, mapping = aes(x = resid)) + geom_histogram() + labs(title = "Distribution of Residuals")
```

```{r resid-plot}
ggplot(data = houses, mapping = aes(x = predicted, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Predicted Logprice")

ggplot(data = houses, mapping = aes(x = floorsCat, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Number of Floors")

ggplot(data = houses, mapping = aes(x = sqftCent, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Interior Square Footage")

ggplot(data = houses, mapping = aes(x = bedroomsCent, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Number of Bedrooms")

ggplot(data = houses, mapping = aes(x = bathroomsCent, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Number of Bathrooms")

ggplot(data = houses, mapping = aes(x = waterfront, y = resid)) + geom_point() + geom_hline(yintercept = 0, color ="red") + labs(title = "Residual Plot of Logprice Residuals vs. Waterfront")
```

```{r qqplot}
ggplot(data = houses, mapping = aes(sample = resid)) + 
  stat_qq() + 
  stat_qq_line() +
  labs(title = "Normal QQ Plot of Residuals")
```

Linearity is satisfied for all predictor variables except number of floors because the scatterplots for the other variables show relatively positive correlations with logprice that follow a linear relationship, but the scatterplot between logprice and number of floors does not show a linear relationship.

Normality is satisfied because the distribution of residuals for the logprice model is normal and the normal qq plot of residuals follows the line of best fit.

Constant Variance is not satsified for any of the predictor variables because the the variation in residuals are not constant across any of the predictor variables.

Independence is not satisfied because a house's price is not completely indpendent of other houses' prices. For example, if the economy is not doing well, house prices might decrease in general, or houses might be priced lower to compete in the market. Also, houses in the same neighborhood might all be priced similarly.

#### Interaction
```{r model-interaction}
logprice_model <- lm(logprice ~ floorsCat + sqftCent + bedroomsCent + bathroomsCent + waterfront + waterfront * bedroomsCent, data = houses)
kable(tidy(logprice_model, conf.int = TRUE, level = 0.95),digits=5)
```

The interaction between `waterfront` and `bedroomsCent` is not significant because the p-value is 0.486, which is higher than the alpha level of 0.05. 

### Overall (do not delete!)

